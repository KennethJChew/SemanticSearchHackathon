{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "import pandas as pd\n",
    "from typing import List,Tuple\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Model choices are:-\n",
    "    1. large - length of embeddings per token is 4096\n",
    "    2. small - length of embeddings per token is 1024\n",
    "    3. multilingual-22-12\n",
    "    \"\"\"\n",
    "co = cohere.Client(\"7lUDtMMSa1bVCEVIKEOms0jPImRnselfUQucOH5v\")\n",
    "    \n",
    "response = co.embed(\n",
    "  model='small',\n",
    "  texts=[\"Milkshake\"])\n",
    "# print('Embeddings: {}'.format(response.embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(response.embeddings[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cos_sim(text: str) -> List[Tuple[str, float]]:\n",
    "    \"\"\"Return cosine similarity scores (sorted in descending order) of corpus documents with input text.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text to be compared against corpus.\n",
    "\n",
    "    Returns:\n",
    "        List[Tuple[str, float]]: Corpus documents and cosine similarity scores, sorted in descending order.\n",
    "    \"\"\"\n",
    "    res = [\n",
    "        (\"Patent_A\", 0.8),\n",
    "        (\"Patent_B\", 0.7),\n",
    "        (\"Patent_C\", 0.6),\n",
    "    ]\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_patent_desc(text: str) -> str:\n",
    "    \"\"\"Generate new patent description.\n",
    "\n",
    "    Args:\n",
    "        text (str): Input text.\n",
    "\n",
    "    Returns:\n",
    "        str: New patent description.\n",
    "    \"\"\"\n",
    "    res = \"Description of new patent.\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datafile = pd.read_csv(\"sample.tsv\",sep=\"\\t\")\n",
    "corpus_set = datafile.iloc[:1]\n",
    "test_set = datafile.iloc[1:]\n",
    "corpus_abstracts = corpus_set[\"ABSTRACT\"]\n",
    "test_abstract = test_set[\"ABSTRACT\"]\n",
    "\n",
    "corpus_text = list(corpus_abstracts)\n",
    "test_text = list(test_abstract)\n",
    "# abstracts = datafile[\"ABSTRACT\"]\n",
    "# abstract_list = list(abstracts)\n",
    "# print(abstract_list)\n",
    "# datafile.head(5)\n",
    "\n",
    "print(corpus_abstracts[0])\n",
    "print(test_abstract[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = co.embed(texts=test_text,model=\"small\")\n",
    "corpus_results = co.embed(texts=corpus_text,model=\"small\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings = test_results.embeddings\n",
    "corpus_embeddings = corpus_results.embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embeddings_arr = np.array(test_embeddings)\n",
    "corpus_embeddings_arr = np.array(corpus_embeddings)\n",
    "print(test_embeddings_arr.shape)\n",
    "print(corpus_embeddings_arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshaped_test_embeddings = np.reshape(test_embeddings,(1024,-1))\n",
    "# reshaped_test_embeddings.shape\n",
    "# reshaped_corpus_embeddings = np.reshape(corpus_embeddings,(1024,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarities = []\n",
    "for each in corpus_embeddings_arr:\n",
    "    cos_sim = dot(test_embeddings_arr, each)/(norm(test_embeddings_arr)*norm(each))\n",
    "    cosine_similarities.append(cos_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cosine_similarities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [array([0.38826797]), array([0.6634463]), array([0.4280255]), array([0.31543467]), array([0.40113314]), array([0.22327371]), array([0.35148772]), array([0.48820173]), array([0.69228912]), array([0.30005143]), array([0.18081221]), array([0.69498284]), array([0.52173298]), array([0.40174261]), array([0.6032165]), array([0.46532465]), array([0.55992382]), array([0.48836531]), array([0.60111407]), array([0.18527497]), array([0.42137111])]\n",
    "data = pd.read_csv(\"sample.tsv\",sep=\"\\t\")\n",
    "cor = data.to_dict(orient=\"records\")\n",
    "print(cor[1][])\n",
    "\n",
    "# for each in cor.items():\n",
    "#     print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PaperParser():\n",
    "    def __init__(self,corpus_text=None,model=\"small\") -> None:\n",
    "        self.model = model\n",
    "        self.models = [\"small\",\"large\",\"multilingual-22-12\"]\n",
    "        self.client = cohere.Client(\"7lUDtMMSa1bVCEVIKEOms0jPImRnselfUQucOH5v\")\n",
    "        self.corpus = None\n",
    "        # self.corpus_embeddings = co.embed(texts=corpus_text,model=model).embeddings\n",
    "    \n",
    "\n",
    "    def create_corpus(self,datafile,file_type=\"csv\"):\n",
    "        if type != \"csv\":\n",
    "            data = pd.read_csv(datafile,sep=\"\\t\")\n",
    "        else:\n",
    "            data = pd.read_csv(datafile)\n",
    "        corpus = {}\n",
    "        corpus_records = data.to_dict(orient=\"records\")\n",
    "\n",
    "        for idx,record in enumerate(corpus_records):\n",
    "            corpus[idx] = record\n",
    "        self.corpus = corpus\n",
    "\n",
    "    def get_corpus_embeddings(self):\n",
    "        # indices are as follows:\n",
    "        # 0 : dictionary index\n",
    "        # 1 : Title\n",
    "        # 2 : Language\n",
    "        # 3 : Abstract\n",
    "        # 4 : URL\n",
    "        corpus_texts = []\n",
    "        for idx in self.corpus:\n",
    "            corpus_texts.append(self.corpus[idx][\"ABSTRACT\"])\n",
    "        if len(corpus_texts) > 16:\n",
    "            pass\n",
    "        corpus_embeddings = self.client.embed(texts=corpus_texts,model=self.model).embeddings\n",
    "        for idx,embedding in enumerate(corpus_embeddings):\n",
    "            self.corpus[idx][\"EMBEDDING\"] = embedding\n",
    "        \n",
    "\n",
    "    def get_cos_sim(self,text: str) -> List[Tuple[str, float]]:\n",
    "        \"\"\"Return cosine similarity scores (sorted in descending order) of corpus documents with input text.\n",
    "\n",
    "        Args:\n",
    "            text (str): Input text to be compared against corpus.\n",
    "\n",
    "        Returns:\n",
    "            List[Tuple[str, float]]: Corpus documents and cosine similarity scores, sorted in descending order.\n",
    "        \"\"\"\n",
    "        # Get embedding\n",
    "        text_embeddings = self.client.embed(texts=text,model=self.model).embeddings\n",
    "        # Get cosine similarities\n",
    "        res = []\n",
    "        for record in self.corpus.items():\n",
    "            cos_sim = dot(text_embeddings, record[1][\"EMBEDDING\"])/(norm(text_embeddings)*norm(record[1][\"EMBEDDING\"]))\n",
    "            res.append((record[1][\"TITLE\"],float(cos_sim)))\n",
    "        res.sort(key=lambda a:a[1],reverse=True)\n",
    "\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datafile = pd.read_csv(\"test.tsv\",sep=\"\\t\")\n",
    "test_abstract = test_datafile[\"ABSTRACT\"]\n",
    "test_text = list(test_abstract)\n",
    "\n",
    "parser = PaperParser()\n",
    "parser.create_corpus(\"corpus.tsv\",file_type=\"tsv\")\n",
    "parser.get_corpus_embeddings()\n",
    "\n",
    "cos_sim_list = parser.get_cos_sim(text=test_text)\n",
    "# parser.corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Farming and gardening tools with two sets of tines', 0.6949828408172631), ('Handle for household and gardening tools', 0.6922891237944154), ('Gardening tool with multiple interchangeable tool heads', 0.6634463023971804), ('Electrical gardening tool with a replaceable working piece', 0.6032164990479286), ('Gardening tool assembled of pointed metal element and wooden stick, comprising fixing unit with inner and outer sleeve', 0.6011140747230448), ('Handle of gardening tool', 0.559923822218539), ('Portable motorised device for gardening tools', 0.521732982296373), ('Ergonomic garden tools', 0.48836531306215786), ('Short-handled, ergonomic garden tools', 0.4882017258395994), ('Gardening tool', 0.46532464809791063), ('Placing rack for gardening tools', 0.42802549944776136), ('Motorized gardening tool', 0.4213711144810016), ('Garden tool', 0.4017426116582123), ('Multifunctional Gardening Tool', 0.4011331428243973), ('Gardening tool', 0.3882679740254629), ('园林工具刹车装置', 0.351487717413807), ('一种园林工具的置物架', 0.31543467194037994), ('Steel 55MnB for domestic gardening tools and preparation method thereof', 0.3000514305565109), ('Multi-purpose gardening tool', 0.22327370869649454), ('Gartengerät mit einem Stahlstiftabschnitt', 0.18527497086856204), ('一种家用园艺工具用钢55MnB及其制备方法', 0.18081221447934023)]\n"
     ]
    }
   ],
   "source": [
    "print(cos_sim_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [(\"Patent_B\", 0.7),(\"Patent_C\", 0.6),(\"Patent_A\", 0.8)]\n",
    "res.sort(key=lambda a:a[1],reverse=True)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = co.generate(  \n",
    "    model='xlarge',  \n",
    "    prompt = \"Write me a 500 word patent application for a gardening tool\",  \n",
    "    max_tokens=40,  \n",
    "    temperature=0.2,  \n",
    "    stop_sequences=[\"--\"])\n",
    "\n",
    "startup_idea = response.generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cohere.Generation {\n",
      "\ttext: .\n",
      "I need a patent application for a gardening tool. The patent application should be 500 words.\n",
      "I will provide the details.\n",
      "I need a patent application for a gardening tool. The patent\n",
      "\tlikelihood: None\n",
      "\ttoken_likelihoods: None\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# for idea in startup_idea:\n",
    "#     print(idea.text)\n",
    "print(startup_idea)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cohere_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a3140b9a8307c5d4052ca5ce7c4e80ebc75753d5fae2c90c0db523a23c774b7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
